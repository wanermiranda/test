{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 187) (119, 187)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('TrainMeu.txt', header=None, sep='\\t')\n",
    "val_df = pd.read_csv('ValMeu.txt', header=None, sep='\\t')\n",
    "print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\n",
      "0     \n",
      "0  173\n",
      "1   13\n",
      "    1\n",
      "0    \n",
      "0  99\n",
      "1  20\n",
      "(186, 186) (186,) (119, 186) (119,)\n",
      "(186, 187) (119, 187) (186,)\n",
      "[  1 100   1   1   1   1   1 100   1   1   1   1   1 100   1   1   1   1\n",
      "   1   1   1   1   1   1   1 100   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1 100   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1 100   1   1   1   1   1   1   1   1   1 100   1   1   1   1   1\n",
      "   1   1   1 100   1   1   1   1   1   1   1 100   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1 100   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1 100   1 100   1   1   1   1   1   1   1 100   1   1\n",
      "   1   1   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "#remove_n = 150\n",
    "#drop_indices = np.random.choice(train_df[train_df[0]==0].index, remove_n, replace=False)\n",
    "#train_df2 = train_df#.drop(drop_indices)\n",
    "print(train_df[[0,1]].groupby(0).count())\n",
    "print(val_df[[0,1]].groupby(0).count())\n",
    "\n",
    "train_vec  = train_df.as_matrix()\n",
    "val_vec  = val_df.as_matrix()\n",
    "\n",
    "train = train_vec[:,1:]\n",
    "target = train_vec[:,0]\n",
    "\n",
    "\n",
    "\n",
    "val = val_vec[:,1:]\n",
    "val_labels = val_vec[:,0]\n",
    "\n",
    "print(train.shape, target.shape, val.shape, val_labels.shape)\n",
    "\n",
    "sample_weight = np.array([500 if i == 1 else 1 for i in target])\n",
    "print(train_vec.shape, val_vec.shape, sample_weight.shape)\n",
    "print(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.97 ms, sys: 1.4 ms, total: 10.4 ms\n",
      "Wall time: 106 ms\n",
      "0.8235294117647058 -0.0162667751118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=3\n",
    "                            , n_jobs=3)\n",
    "\n",
    "%time rf.fit(train, target, sample_weight=sample_weight)\n",
    "predictions = rf.predict(val)\n",
    "right_guesses = 0\n",
    "\n",
    "for idx in range(val.shape[0]): \n",
    "    if predictions[idx] == val_labels[idx]: \n",
    "        right_guesses  += 1\n",
    "\n",
    "accuracy = right_guesses / float(val.shape[0])\n",
    "\n",
    "kappa = cohen_kappa_score(predictions, val_labels)\n",
    "print (accuracy, kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "print (predictions)\n",
    "print (val_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
